# Введение <a name="1"></a>
## Алгоритмы предварительной обработки данных <a name="1_1"></a>
## Алгоритмы машинного обучения <a name="1_2"></a>
### Обучение с учителем <a name="1_2_1"></a>
### Обучение без учителя <a name="1_2_2"></a>
## Типовая вычислительная инфраструктура для машинного обучения  <a name="1_3"></a>
## Проект хакатона <a name="1_4"></a>
## Оборудование и настройка компьютера разработчика <a name="1_5"></a>
# День 1. Управление виртуальным ЦОД <a name="2"></a>
## Доступ к виртальному ЦОД <a name="21"></a>
## Создание виртуальной машины сетевого шлюза и установка ОС <a name="22"></a>
## Создание виртуальной машины в локальной сети и настройка шлюза<a name="24"></a>
## Уcтановка фреймворка Anaconda и Jupyter Notebooks <a name="25"></a>
# День 2. Практикум в Jupyter Notebook <a name="3"></a>
## Методология машинного обучения <a name="3_1"></a>
## Предварительная обработка данных <a name="3_2"></a>
### Очистка данных <a name="3_2_1"></a>
### Масштабирование <a name="3_2_2"></a>
### Уменьшение размерности<a name="3_2_3"></a>
### Алгоритм отбора признаков<a name="3_2_4"></a>
### Обратное удаление признаков<a name="3_2_5"></a>
### Выбор вперед<a name="3_2_6"></a>
### Анализ главных компонентов<a name="3_2_7"></a>
### Независимый компонентный анализ<a name="3_2_8"></a>
### Факторный анализ<a name="3_2_9"></a>
### Многообразное обучение или нелинейное уменьшение размерности<a name="3_2_10"></a>
### Локально линейное вложение<a name="3_2_11"></a>
### Cтохастическое вложение соседей с t-распределением<a name="3_2_12"></a>
### Унифицированная аппроксимация и проекция многообразия<a name="3_2_13"></a>
### Краткий обзор алгоритмов и методов уменьшения размерности <a name="3_2_14"></a>
#### Соотношение пропущенных значений<a name="3_2_14_1"></a>
#### Фильтр низкой дисперсии<a name="3_2_14_2"></a>
#### Фильтр высокой корреляции<a name="3_2_14_3"></a>
#### Случайный лес<a name="3_2_14_4"></a>
#### Факторный анализ<a name="3_2_14_5"></a>
#### Анализ основных компонентов<a name="3_2_14_6"></a>
### Разделение набора данных<a name="3_2_20"></a>
## Практическая часть <a name="3_3"></a>
### Первичный анализ данных <a name="3_3_1"></a>
### Описание задачи и данных <a name="3_3_2"></a>
### Задание <a name="3_3_3"></a>
# День 3. Алгоритмы машинного обучения <a name="4"></a>
## Алгоритмы машинного обучения <a name="4_3"></a>
###  Линейная регрессия<a name="4_3_1"></a>
###  Деревья решений<a name="4_3_2"></a>
###  Метод опорных векторов<a name="4_3_3"></a>
###  Алгоритм k-ближайших соседей<a name="4_3_4"></a>
## Оценка и тестирование модели <a name="4_4"></a>
###  Перекрестная проверка<a name="4_4_1"></a>
###  Улучшение прогнозов с помощью методов ансамбля<a name="4_4_2"></a>
## Практическая часть <a name="4_6"></a>
### Проверка данных <a name="4_6_1"></a>
### Обучение моделей <a name="4_6_2"></a>
### Развертывание модели машинного обучения Python в качестве веб-службы flask<a name="4_6_3"></a>
## Задание <a name="4_7"></a>
## Выбор лучшей модели <a name="4_8"></a>
# День 4. Распознавание образов и компьютерное зрение <a name="5"></a>
## Введение  <a name="5_0"></a>
## Нейронная сеть <a name="5_1"></a>
## Сверточные нейронные сети <a name="5_2"></a>
### Сверточный слой <a name="5_2_1"></a>
### Субдискретизирующий слой <a name="5_2_2"></a>
### Обучение НС <a name="5_2_3"></a>
## Библиотека PyTorch <a name="5_3"></a>
### Постановка задачи  <a name="5_0_1"></a>
## Поиск объектов на изображении с использованием PyTorch <a name="5_4"></a>
### Настройка окружения <a name="5_4_0"></a>
### Поиск набора данных <a name="5_4_1"></a>
### Подготовка набора данных <a name="5_4_3"></a>
### Выбор модели <a name="5_4_2"></a>
### Настройка параметров обучения <a name="5_4_4"></a>
### Проверка обученной модели <a name="5_4_5"></a>
### Конец? <a name="5_4_6"></a>
### Источники <a name="5_4_7"></a>
# День 5. Графы знаний <a name="6"></a>
# Дополнительные источники <a name="a001"></a>
